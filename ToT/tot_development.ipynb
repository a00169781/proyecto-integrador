{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Libraries \n",
    "from openai import OpenAI\n",
    "import os, os.path\n",
    "from datetime import datetime\n",
    "import json\n",
    "import requests\n",
    "import re\n",
    "import copy\n",
    "from os import path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper functions\n",
    "# TODO: move to a common file\n",
    "def get_current_timestamp():\n",
    "  \"\"\"\n",
    "  Returns the current timestamp in the format \"YYYY-MM-DD hh:mm:ss\".\n",
    "  \"\"\"\n",
    "  now = datetime.now()\n",
    "  return now.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "\n",
    "def get_current_date():\n",
    "  \"\"\"\n",
    "  Returns the current date in the format \"YYYY-MM-DD\".\n",
    "  \"\"\"\n",
    "  now = datetime.now()\n",
    "  return now.strftime(\"%Y-%m-%d\")\n",
    "\n",
    "def save_dict_to_drive(data, filename):\n",
    "  \"\"\"Saves a dictionary to a JSON file in Google Drive.\n",
    "\n",
    "  Args:\n",
    "    data: The dictionary to save.\n",
    "    filename: The name of the file to save to (e.g., 'my_data.json').\n",
    "  \"\"\"\n",
    "  # Uncomment the following lines if you are using google colab\n",
    "  # drive.mount('/content/drive')\n",
    "  # filepath = f'/content/drive/MyDrive/Colab/{filename}'\n",
    "\n",
    "  # If you are not using google colab, you can save the file in the current directory\n",
    "  filepath = f'{filename}'\n",
    "  with open(filepath, 'w') as f:\n",
    "    json.dump(data, f, indent=4)\n",
    "  print(f\"Dictionary saved to: {filepath}\")\n",
    "\n",
    "def load_dict_from_drive(filename):\n",
    "  \"\"\"Loads a dictionary from a JSON file in Google Drive.\n",
    "\n",
    "  Args:\n",
    "    filename: The name of the file to load from (e.g., 'my_data.json').\n",
    "\n",
    "  Returns:\n",
    "    The loaded dictionary, or None if the file is not found.\n",
    "  \"\"\"\n",
    "  # Uncomment the following lines if you are using google colab\n",
    "  # drive.mount('/content/drive')\n",
    "  # filepath = f'/content/drive/MyDrive/Colab/{filename}'\n",
    "\n",
    "  # If you are not using google colab, you can load the file from the current directory\n",
    "  filepath = f'{filename}'\n",
    "  try:\n",
    "    with open(filepath, 'r') as f:\n",
    "      data = json.load(f)\n",
    "    print(f\"Dictionary loaded from: {filepath}\")\n",
    "    return data\n",
    "  except FileNotFoundError:\n",
    "    print(f\"File not found: {filepath}\")\n",
    "    return None\n",
    "\n",
    "\n",
    "    # Example usage:\n",
    "    # my_dict = {'key1': 'value1', 'key2': 'value2'}\n",
    "    # save_dict_to_drive(my_dict, 'my_dictionary.json')\n",
    "\n",
    "    # loaded_dict = load_dict_from_drive('my_dictionary.json')\n",
    "    # if loaded_dict:\n",
    "    #   print(loaded_dict)\n",
    "def extract_thoughts(response):\n",
    "    \"\"\"\n",
    "    Extracts thoughts from a given response string.\n",
    "\n",
    "    This function searches for content enclosed in <thought> tags within the response,\n",
    "    removes any leading non-alphabetic characters, and returns a list of cleaned thoughts.\n",
    "\n",
    "    Args:\n",
    "        response (str): The input string containing thoughts enclosed in <thought> tags.\n",
    "\n",
    "    Returns:\n",
    "        list: A list of extracted and cleaned thoughts.\n",
    "\n",
    "    Example:\n",
    "        >>> response = \"<thought>1. First thought</thought><thought>2. Second thought</thought>\"\n",
    "        >>> extract_thoughts(response)\n",
    "        ['First thought', 'Second thought']\n",
    "    \"\"\"\n",
    "    thought_pattern = r'<thought>(.*?)</thought>'\n",
    "    thoughts = re.findall(thought_pattern, response, re.DOTALL)\n",
    "    return [re.sub(r'^[^A-Z]*', '', thought.strip()) for thought in thoughts]\n",
    "\n",
    "def extract_score(text):\n",
    "    # Regular expression to match a number between 0.1 and 1.0\n",
    "    pattern = r'\\b(0\\.1|0\\.[2-9]|1\\.0)\\b'\n",
    "    \n",
    "    # Find all matches in the text\n",
    "    matches = re.findall(pattern, text)\n",
    "    \n",
    "    # If a match is found, return the first one as a float\n",
    "    if matches:\n",
    "        return float(matches[0])\n",
    "    \n",
    "    # If no valid score is found, return None\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prompts dictionary\n",
    "# for further explanation of the prompts, see ToTprompts.md\n",
    "# TODO: move to a common file\n",
    "prompt_dict = {\n",
    "    \"tot_generator\": \"\"\"\n",
    "You are an expert problem-solving agent designed to provide accurate and detailed thoughts that help to undertnad and and solve causal relationships.\n",
    "Your task is to generate five steps or thoughts that helps to solve a given problem. Just present the thoughts, do not answer the question or arrive at any conclusion\n",
    "\n",
    "### Instructions:\n",
    "\n",
    "1. **Understand the Problem:**\n",
    "   - Carefully analyze the problem provided by the user.\n",
    "   - Identify the question that the user is asking.\n",
    "   - Analyze how the question relates to the context of the problem.\n",
    "   - Break down the problem into smaller, manageable parts if necessary.\n",
    "   - Formulate a clear understanding of the problem before proceeding.\n",
    "\n",
    "2. **Generate Thoughts:**\n",
    "   - Create five thoughts or steps toward solving the problem.\n",
    "   - The thoughts should be clear, concise, and logical.\n",
    "   - The thoughts should make the question easier to answer.\n",
    "   - For each thought or step, document your reasoning, ensuring that it is logical and well-founded.\n",
    "   - Present the thoughts inside these tags <thought></thought>\n",
    "\"\"\",\n",
    "    \"tot_evaluator\": \"\"\"\n",
    "You are an expert problem-solving agent designed to critically evaluate the quality of a thought process. \n",
    "Your task is to follow a structured approach to assess the quality of a thought related to how useful it can be to solve the given problem. \n",
    "You will be given a problem and a thought, and you will need to provide a rating for the thought on a scale of 0.1 to 1.0. \n",
    "This rating should reflect the accuracy, quality, and usefulness of the thought to solve the problem using only the information provided in the problem text. \n",
    "Just present the score of the thought evaluation, do not answer the question or arrive at any conclusion\n",
    "\n",
    "### Instructions:\n",
    "\n",
    "1. **Understand the Problem:**\n",
    "   - Carefully analyze the problem provided by the user.\n",
    "   - Break down the problem into smaller, manageable parts if necessary.\n",
    "   - Formulate a clear understanding of the problem before proceeding.\n",
    "\n",
    "2. **Understand the Thought:**\n",
    "   - Carefully analyze the thought provided by the user.\n",
    "   - Break down the thought into smaller, manageable parts if necessary.\n",
    "   - Formulate a clear understanding of the thought before proceeding.\n",
    "\n",
    "3. **Thought Evaluation:**\n",
    "   - Evaluate the accuracy and quality of the thought.\n",
    "   - Evaluate the scope of the thought, the thought must be tested only on the given problem context.\n",
    "   - Assign an evaluation score between 0.1 and 1.0. Use the following guidelines:\n",
    "     - **0.1 to 0.4:** The thought is flawed, inaccurate, or incomplete.\n",
    "     - **0.5 to 0.7:** The thought is partially correct but may lack detail or full accuracy.\n",
    "     - **0.8 to 1.0:** The thought is accurate, complete, and well-reasoned.\n",
    "    \"\"\",\n",
    "    \"tot_further_development\": \"\"\"\n",
    "You are an expert problem-solving agent designed to provide accurate and detailed thoughts that help to undertnad and and solve causal relationships.\n",
    "You will be given a list of thoughts that will help you to understand and solve a problem.\n",
    "Your task is to generate a new step or thought that helps to solve the problem. Just present the thought, do not answer the question or arrive at any conclusion.\n",
    "\n",
    "### Instructions:\n",
    "\n",
    "1. **Understand the Problem:**\n",
    "   - Carefully analyze the problem provided by the user.\n",
    "   - Identify the previous steps and thoughts that were generated.\n",
    "   - Analyze the previous thoughts and steps to understand the current state of the problem.\n",
    "   - Identify the question that the user is asking.\n",
    "   - Analyze how the question relates to the context of the problem and the previous steps and thoughts.\n",
    "   - Break down the problem into smaller, manageable parts if necessary.\n",
    "   - Formulate a clear understanding of the problem before proceeding.\n",
    "\n",
    "2. **Generate a Thought:**\n",
    "   - Create a single thought or step toward solving the problem.\n",
    "   - The thought should be clear, concise, and logical.\n",
    "   - The thought should make the question easier to answer.\n",
    "   - The thought should be based on the previous steps and thoughts.\n",
    "   - The thought should be a logical extension of the previous thoughts.\n",
    "   - For each thought or step, document your reasoning, ensuring that it is logical and well-founded.\n",
    "   - Present the thought inside these tags <thought></thought>\n",
    "    \"\"\",\n",
    "    \"tot_branch_selector\": \"\"\"\n",
    "        You are an expert problem-solving agent designed to critically evaluate the quality of a thought process. \n",
    "Given a problem and serveral sets of thoughts, your tasks is to select the most useful set of thoughts that are more likely to help to solve the given problem.\n",
    "Analyze each set in detail and select the best set taking into account the accuracy, completeness and well-reasoned of the thoughts.\n",
    "\n",
    "### Instructions:\n",
    "\n",
    "1. **Understand the Problem:**\n",
    "   - Carefully analyze the problem provided by the user.\n",
    "   - Break down the problem into smaller, manageable parts if necessary.\n",
    "   - Formulate a clear understanding of the problem before proceeding.\n",
    "\n",
    "2. **Select the best set of thoughts:**\n",
    "   - Analyze each set of thoughts in detail.\n",
    "   - Evaluate the accuracy, completeness and well-reasoned of the thoughts.\n",
    "   - Select the best set of thoughts based on the evaluation.\n",
    "   - Present the best set of thoughts, do not answer the question or arrive at any conclusion.\n",
    "\n",
    "3. **Conclusion:**\n",
    "   - Based on your analysis, select the best set of thoughts that are more likely to help to solve the given problem.\n",
    "   - End with \"The best choise is <set>\" where <set> is the best set of thoughts.\n",
    "\"\"\",\n",
    "    \"tot_final_answer\": \"\"\"\n",
    "You are an AI language model specialized in determining causal relationships. \n",
    "You will be given a problem and a set of thoughts that are more likely to help to solve the given problem.\n",
    "Your task is to synthesize a final answer to the problem based on the given set of thoughts.\n",
    "You will need to provide a clear, concise response. Your answer should\n",
    "\n",
    "1. **Understand the Problem:**\n",
    "   - Carefully analyze the problem provided by the user.\n",
    "   - Break down the problem into smaller, manageable parts if necessary.\n",
    "   - Formulate a clear understanding of the problem before proceeding.\n",
    "\n",
    "2. **Understand the Thoughts:**\n",
    "   - Carefully analyze the thoughts provided by the user.\n",
    "   - Break down the thoughts into smaller, manageable parts if necessary.\n",
    "   - Formulate a clear understanding of the thoughts before proceeding.\n",
    "\n",
    "3. **Synthesize the Final Answer:**\n",
    "   - Based on the thoughts, synthesize a final answer to the problem.\n",
    "   - Ensure the final answer is comprehensive and addresses all aspects of the problem.\n",
    "   - Present the final answer in a clear, concise manner.\n",
    "\n",
    "3. **Conclusion:**\n",
    "   - End your response with \"The answer is Yes.\" or \"The answer is No.\" based on your analysis.\n",
    "\n",
    "\"\"\"\n",
    "}   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dictionary loaded from: ./output/tot_step_1.json\n"
     ]
    }
   ],
   "source": [
    "# This code will run the ToT generator for each task in the dataset\n",
    "# it will create five thoughts for each task and save them in a json file\n",
    "output_filename = \"./tot_output/tot_step_2.json\"\n",
    "\n",
    "\n",
    "tot_further_development_model_params = {\n",
    "    \"model\": \"gpt-4o-mini\",\n",
    "    \"messages\": [\n",
    "        {\"role\": \"system\", \"content\": prompt_dict[\"tot_further_development\"]},\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"example['input']\"\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "\n",
    "tot_evaluator_model_params = {\n",
    "    \"model\": \"gpt-4o-mini\",\n",
    "    \"messages\": [\n",
    "        {\"role\": \"system\", \"content\": prompt_dict[\"tot_evaluator\"]},\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"thought\"\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "\n",
    "#print(model_params['messages'][0])\n",
    "\n",
    "data = load_dict_from_drive('./output/tot_step_1.json')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dictionary loaded from: ./output/tot_step_1.json\n",
      "Processing thought 1/1\n",
      "Processing thought 1/1\n",
      "Processing thought 1/1\n",
      "Processing thought 1/1\n",
      "Dictionary saved to: ./output/tot_step_2.json\n"
     ]
    }
   ],
   "source": [
    "data = load_dict_from_drive('./output/tot_step_1.json')\n",
    "OPENAI_API_KEY = os.getenv('OPENAI_API_KEY')\n",
    "client = OpenAI(\n",
    "    api_key = OPENAI_API_KEY,\n",
    ")\n",
    "\n",
    "for idx, result in enumerate(data['results']):\n",
    "  if idx == 1:\n",
    "    break\n",
    "  #print(f\"Processing example {idx+1}/{len(data['results'])}\")\n",
    "  input = result['input']\n",
    "  for i,branch in enumerate(result['branches']):\n",
    "    #print(f\"Processing branch {i+1}/{len(result['branches'])}\")\n",
    "    if idx == 1:\n",
    "      break\n",
    "    if branch['dead_branch'] == True:\n",
    "      continue\n",
    "    \n",
    "    thoughts_string = '\\n'.join([f\"{i+1}. {thought}\" for i, thought in enumerate(branch['thoughts'])])\n",
    "    tot_further_development_query = f\"\"\"Problem: {input}\n",
    "Thoughts: {thoughts_string}\n",
    "\"\"\" \n",
    "    #print(tot_further_development_query) \n",
    "    completion = client.chat.completions.create(\n",
    "      model=tot_further_development_model_params['model'],\n",
    "      messages=[\n",
    "          tot_further_development_model_params['messages'][0],\n",
    "          {\n",
    "              \"role\": \"user\",\n",
    "              \"content\": tot_further_development_query\n",
    "          }\n",
    "      ]\n",
    "    )\n",
    "    response = completion.choices[0].message.content\n",
    "    #print(response)\n",
    "    new_thoughts = extract_thoughts(response)\n",
    "    #print(new_thoughts)\n",
    "    for n,thought in enumerate(new_thoughts):\n",
    "      print(f\"Processing thought {n+1}/{len(new_thoughts)}\")\n",
    "      tot_evaluator_query = f\"\"\"Problem: {input}\n",
    "Thought: {thought}\n",
    "\"\"\"\n",
    "#      print(tot_evaluator_query)\n",
    "      completion = client.chat.completions.create(\n",
    "          model=tot_evaluator_model_params['model'],\n",
    "          messages=[\n",
    "                 tot_evaluator_model_params['messages'][0],\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": tot_evaluator_query\n",
    "            }\n",
    "          ]\n",
    "      )\n",
    "      score_response = completion.choices[0].message.content\n",
    "      score = extract_score(score_response)\n",
    "      branch['nodes'].append({\n",
    "        \"prompt\": \"tot_evaluator\",\n",
    "        \"input\": tot_further_development_query,\n",
    "        \"output\": response,\n",
    "        \"thoughts\": new_thoughts,\n",
    "        \"scores\": [score]\n",
    "      })\n",
    "  \n",
    "    branch['thoughts'].append(new_thoughts)\n",
    "    branch['scores'].append(score)\n",
    "    branch['avg_score'] = sum(branch['scores'])/len(branch['scores'])\n",
    "    branch_thoughts_string = '\\n'.join([f\"{i+1}. {thought}\" for i, thought in enumerate(branch['thoughts'])])\n",
    "    \n",
    "    fully_developed_input_string = f\"\"\"Problem: {input}\n",
    "Thoughts: {branch_thoughts_string}\n",
    "\"\"\" \n",
    "    branch['fully_developed_input'] = fully_developed_input_string\n",
    "\n",
    "    for score in branch['scores']:\n",
    "      if score < 0.8:\n",
    "        branch['dead_branch'] = True\n",
    "        break\n",
    "      \n",
    "    #print(new_thought)\n",
    "\n",
    "#    thoughts = extract_thoughts(response)\n",
    "#    result['thoughts']['output'] = response\n",
    "#    result['thoughts']['thoughts'] = thoughts\n",
    "#\n",
    "#  result['scores'] = []\n",
    "#  scores = []\n",
    "#  for thought in thoughts:\n",
    "#    completion = client.chat.completions.create(\n",
    "#          model=tot_evaluator_model_params['model'],\n",
    "#          messages=[\n",
    "#               tot_evaluator_model_params['messages'][0],\n",
    "#               {\n",
    "#                  \"role\": \"user\",\n",
    "#                  \"content\": thought\n",
    "#              }\n",
    "#          ]\n",
    "#      )\n",
    "#    score = completion.choices[0].message.content\n",
    "#    #print(thought)\n",
    "#    #print(score)\n",
    "#\n",
    "#    result['scores'].append({\n",
    "#      \"prompt\": \"tot_evaluator\",\n",
    "#      \"input\": thought,\n",
    "#      \"output\": score,\n",
    "#      \"score\": extract_score(score)\n",
    "#    })\n",
    "#  llm_output['results'].append(copy.deepcopy(result))\n",
    "#  if idx == 2:\n",
    "#    # Uncomment to stop the execution after the first 2 questions\n",
    "#     #break\n",
    "#    pass\n",
    "save_dict_to_drive(data, \"./output/tot_step_2.json\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pintegrador",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
